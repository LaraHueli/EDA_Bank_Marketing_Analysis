# üìä An√°lisis de Marketing Bancario

##  Descripci√≥n
Este proyecto tiene como objetivo realizar un An√°lisis Exploratorio de Datos (EDA) sobre una campa√±a de marketing bancario. Se han aplicado diferentes t√©cnicas de limpieza, transformaci√≥n y an√°lisis para obtener insights que ayuden a mejorar la efectividad de la campa√±a

###  **1Ô∏è‚É£ Primera sesi√≥n: Configuraci√≥n inicial**
1. **Creaci√≥n del repositorio en GitHub** y organizaci√≥n del entorno de trabajo.
2. **Estructura de carpetas y archivos** (`.gitignore`, `venv`, `requirements.txt`).
3. **Carga de datos brutos** en la carpeta `data/`.
4. **Importaci√≥n de librer√≠as** necesarias para el an√°lisis (`pandas`, `numpy`).

## üìÇ Estructura de las carpetas del Proyecto
```
üìÅ data/         # Datos crudos y procesados
üìÅ notebooks/    # Notebooks de Jupyter con el an√°lisis
üìÅ src/          # Scripts de procesamiento
üìÅ results/      # Gr√°ficos y conclusiones
üìÑ README.md     # Descripci√≥n del proyecto
```
## üõ† Requerimientos
Este proyecto utiliza **Python 3.8** y requiere las siguientes bibliotecas:
- `pandas`
- `numpy`
- `jupyter`
-  `matplotlib`
- `seaborn`
## üìö Documentaci√≥n de las Librer√≠as Utilizadas
Durante el an√°lisis de datos utilizamos diversas librer√≠as de Python que facilitaron la manipulaci√≥n, limpieza y visualizaci√≥n de datos. A continuaci√≥n, se incluyen enlaces a sus respectivas documentaciones:
- [Pandas] (https://pandas.pydata.org/docs/) - Manipulaci√≥n y an√°lisis de datos en estructuras tabulares.
- [NumPy] (https://numpy.org/doc/) - Operaciones matem√°ticas y manejo de arrays multidimensionales.
- [Matplotlib] (https://matplotlib.org/stable/contents.html) - Creaci√≥n de gr√°ficos est√°ticos, animados e interactivos.
- [Seaborn] (https://seaborn.pydata.org/) - Visualizaci√≥n de datos basada en Matplotlib con una interfaz m√°s sencilla y atractiva.
  Esto permite a cualquier persona que revise el an√°lisis acceder r√°pidamente a la documentaci√≥n de cada librer√≠a para entender mejor su uso.
---  

###  **2Ô∏è‚É£ Segunda sesi√≥n: Exploraci√≥n Preliminar de Datos (EDA Preliminar)**
#### üîç **Estudio previo de combinaci√≥n de tablas**
üîÑ Fusi√≥n de bank-additional.csv y customer-details.csv
Para un an√°lisis m√°s completo, se decidi√≥ combinar ambos datasets en un √∫nico archivo denominado df_combinado.csv.
Pasos realizados:
‚úÖ Se identific√≥ la columna clave (id_) para la fusi√≥n.
‚úÖ Se aplic√≥ un left merge para conservar todos los registros de bank-additional.csv.
‚úÖ Se eliminaron columnas redundantes (Income, Teenhome, etc.) y valores duplicados.
‚úÖ Se verificaron los tipos de datos y se ajustaron seg√∫n correspond√≠a.
- **An√°lisis de los resultados**:
La combinaci√≥n de los datasets permiti√≥ obtener una visi√≥n m√°s amplia de la informaci√≥n, consolidando datos de campa√±as previas con caracter√≠sticas adicionales de los clientes. Se observaron algunas diferencias en la estructura de los datos, las cuales fueron corregidas para garantizar coherencia en el an√°lisis.

A partir de este dataset unificado, se proceder√° con un EDA preliminar.

#### üìä **Dimensiones e informaci√≥n del dataset**
El dataset contiene **43,000 filas** y **23 columnas**. A continuaci√≥n, se detalla la informaci√≥n clave sobre los tipos de datos y los valores no nulos de cada columna:

| **Columna**       | **Tipo de dato** | **Valores no nulos** | **Descripci√≥n**                                                        |
|-------------------|------------------|----------------------|----------------------------------------------------------------------- |
| `age`             | float64          | 37,880               | Edad del cliente (valores nulos = 5,120).                              |
| `job`             | object           | 42,655               | Profesi√≥n del cliente (valores nulos = 345).                           |
| `marital`         | object           | 42,915               | Estado civil del cliente (valores nulos = 85).                         |
| `education`       | object           | 41,193               | Nivel educativo del cliente (valores nulos = 1,807).                   |
| `default`         | float64          | 34,019               | Indica si el cliente tiene un cr√©dito en mora (valores nulos = 8,981). |
| `housing`         | float64          | 41,974               | Indica si el cliente tiene un pr√©stamo hipotecario.                    |
| `loan`            | float64          | 41,974               | Indica si el cliente tiene un pr√©stamo personal.                       |
| `contact`         | object           | 43,000               | Tipo de contacto utilizado (sin valores nulos).                        |
| `duration`        | int64            | 43,000               | Duraci√≥n de la √∫ltima llamada en segundos (sin valores nulos).         |
| `campaign`        | int64            | 43,000               | N√∫mero de contactos realizados durante esta campa√±a (sin valores nulos)|
| `pdays`           | int64            | 43,000               | N√∫mero de d√≠as desde el √∫ltimo contacto con el cliente.                |
| `previous`        | int64            | 43,000               | N√∫mero de contactos realizados antes de esta campa√±a.                  |
| `poutcome`        | object           | 43,000               | Resultado de la campa√±a de marketing anterior.                         |
| `emp.var.rate`    | float64          | 43,000               | Tasa de variaci√≥n del empleo.                                          |
| `cons.price.idx`  | float64          | 42,529               | √çndice de precios al consumidor (valores nulos = 471).                 |
| `cons.conf.idx`   | object           | 43,000               | √çndice de confianza del consumidor.                                    |
| `euribor3m`       | float64          | 33,744               | Tasa de inter√©s del Euribor a 3 meses (valores nulos = 9,256).         |
| `nr.employed`     | object           | 43,000               | N√∫mero total de empleados (indicador macroecon√≥mico).                  |
| `y`               | object           | 43,000               | Variable objetivo: indica si el cliente acept√≥ una oferta o producto.  |
| `date`            | object           | 43,000               | Fecha asociada al contacto o registro.                                 |
| `latitude`        | float64          | 43,000               | Latitud del cliente (sin valores nulos).                               |
| `longitude`       | float64          | 43,000               | Longitud del cliente (sin valores nulos).                              |
| `id`              | object           | 43,000               | Identificador √∫nico del cliente.                                       |
- **N√∫mero de filas**: 43,000
- **N√∫mero de columnas**: 23
La columna  `y`  es binaria, donde 0 representa que el cliente se suscribi√≥ (yes) y 1 que no se suscribi√≥ (no).
 
#### Observaciones:
- **Valores nulos**: Varias columnas presentan valores nulos, como age (5,120) y default (8,981), que se tratar√°n en la limpieza.
- **Tipos de datos**: Existen columnas num√©ricas y categ√≥ricas que requieren ajustes en su formato antes del an√°lisis.
- **Duplicados**: No se han identificado filas duplicadas.

 ### Transformaci√≥n del Dataset
 **Copia del dataset**  
Se cre√≥ una copia del dataset para evitar modificaciones accidentales en los datos originales utilizando .copy() de pandas.

A partir de este an√°lisis preliminar, se proceder√° a la limpieza de datos para preparar el dataset para un an√°lisis m√°s profundo.

###  **3Ô∏è‚É£ Tercera sesi√≥n: Transformaci√≥n del Dataset**

### üîç Creaci√≥n de la funci√≥n `eda_preliminar`
Como primer paso en la limpieza de datos, hemos desarrollado la funci√≥n `eda_preliminar`, la cual nos permite obtener una visi√≥n general del dataset. Esta funci√≥n realiza las siguientes tareas:

- Muestra una muestra aleatoria (`sample(5)`) para observar algunos registros.
- Presenta informaci√≥n detallada sobre las columnas (`info()`), incluyendo tipos de datos y valores no nulos.
- Calcula el porcentaje de valores nulos (`isnull()`).
- Verifica si hay filas duplicadas (`duplicated()`).
- Identifica las columnas categ√≥ricas (`select_dtypes(include='object')`).
- Muestra la distribuci√≥n de valores (`value_counts()`) en las variables categ√≥ricas.

## üìä Resultados del `eda_preliminar`
### Tipos de datos inconsistentes
- Algunas columnas que deber√≠an ser **num√©ricas** (`float64` o `int64`) est√°n siendo interpretadas como **object** (string en Pandas).
- **Ejemplos**: `cons_price_idx`, `cons_conf_idx` y `nr_employed` deber√≠an ser `float64`, pero Pandas las considera `object`.
- üîπ **Acci√≥n tomada**: Se corrigi√≥ el formato eliminando caracteres extra√±os (como comas en los n√∫meros) y convirtiendo estas columnas a `float64`.

### Valores nulos (`isnull()`)
#### Las columnas con m√°s valores nulos:
- `default`: **20.89%** de valores nulos.
- `euribor3m`: **21.53%** de valores nulos.
- üîπ **Pendiente de tratamiento**: A√∫n no se han reemplazado valores nulos. Se decidir√° en una etapa posterior c√≥mo manejarlos.

### Filas duplicadas (`duplicated()`)
- **No hay filas duplicadas** en el dataset, lo cual es positivo. ‚úÖ

### Distribuci√≥n de valores (`value_counts()`)
#### **Columna `job`**:
- **Categor√≠a m√°s com√∫n**: `admin.` con **10,873 registros**.
- **Categor√≠a menos com√∫n**: `student` con **903 registros**.
#### **Columna `marital`**:
- **Mayor√≠a de clientes casados (`married`)**.
- **Menos frecuentes**: `single` y `divorced`.
#### **Columna `education`**:
- **Mayor√≠a de clientes con t√≠tulo universitario (`university.degree`)**.
- **Las categor√≠as `basic.4y`, `basic.6y`, `basic.9y` fueron unificadas en una sola (`basic`).**

## üîÑ Limpieza y Preprocesamiento de Datos
### Conversi√≥n de valores a min√∫sculas  
Se estandarizaron los valores de las siguientes columnas para evitar inconsistencias en las categor√≠as:  
- **`job`**, **`marital`**, **`contact`**, **`education`**.
### Unificaci√≥n de categor√≠as  
- En **`education`**, las categor√≠as **`basic.4y`**, **`basic.6y`**, y **`basic.9y`** fueron unificadas en **`basic`** para simplificaci√≥n.  
- Se corrigieron inconsistencias en **`poutcome`** para garantizar uniformidad.  
### Eliminaci√≥n de columnas irrelevantes  
- Se eliminaron **`latitude`** y **`longitude`** por no aportar valor relevante al an√°lisis.  
- Se elimin√≥ **`date`** tras extraer **`year`**, **`month`** y **`day`** como variables separadas.
### Transformaci√≥n de tipos de datos  
Se realizaron las siguientes conversiones para asegurar consistencia en los datos:  
- **`age`**, **`housing`**, **`loan`** fueron convertidos de `float` a `int`.  
- **`cons_price_idx`**, **`cons_conf_idx`**, **`euribor3m`**, **`nr_employed`** fueron convertidos de `object` a `float`

‚úÖ **El dataset limpio ha sido guardado como `bank_limpio.csv` y est√° listo para an√°lisis posteriores.**

###  **4Ô∏è‚É£ Cuarta sesi√≥n: An√°lisis de Variables Categ√≥ricas**

## üî¢ 1 C√°lculo de Valores Nulos
Antes de tomar decisiones sobre la imputaci√≥n o eliminaci√≥n de datos, se calcul√≥ el porcentaje de valores nulos en cada columna categ√≥rica.
Para esto, se utiliz√≥ la funci√≥n `calcular_porcentaje_nulos(df)`, ubicada en `sp_eda.py`, que:
- **N√∫mero total de valores nulos por columna.**
- **Porcentaje de valores nulos en relaci√≥n con el total de filas del dataset.**

üîπ **Ejemplo de uso:**
```python
from src.sp_eda import calcular_porcentaje_nulos
porcentaje_nulos = calcular_porcentaje_nulos(df)
print(porcentaje_nulos)
```
### üîç Hallazgos iniciales:
- `poutcome` ten√≠a un **86%** de valores nulos, lo que motiv√≥ su eliminaci√≥n.
- `education`, `job` y `marital` ten√≠an valores nulos menores al **5%**, por lo que se opt√≥ por imputarlos en lugar de eliminarlos.

## üî¢ 2 Gesti√≥n de Valores Nulos
Tras analizar los valores nulos, se decidi√≥:
| **Columna**  | **% de Nulos** | **M√©todo de Imputaci√≥n** | **Justificaci√≥n** |
|-------------|--------------|------------------|----------------------------|
| `job`       | 1.95%        | "unknown"       | No se identific√≥ un patr√≥n claro, se agreg√≥ "unknown" como categor√≠a adicional. |
| `marital`   | 0.20%        | "unknown"       | La baja cantidad de nulos permite una imputaci√≥n sin impacto significativo en la distribuci√≥n. |
| `education` | 4.20%        | "unknown"       | Se decidi√≥ agrupar los valores nulos en "unknown" para evitar sesgar los datos. |
| `poutcome`  | 86%          | Eliminada        | El alto porcentaje de nulos hac√≠a que la variable no aportara informaci√≥n relevante. |

üìå **Justificaci√≥n del Relleno con "unknown":**
- No hab√≠a una relaci√≥n clara entre los valores nulos y otras variables.
- Se evalu√≥ imputar los valores con la moda, pero en `job` y `education` hab√≠a una alta variabilidad, lo que podr√≠a distorsionar los resultados.
- Se prob√≥ la asignaci√≥n basada en frecuencias, pero la distribuci√≥n no era homog√©nea.
- Se opt√≥ por "unknown" como una categor√≠a adicional para no sesgar el an√°lisis.
Esta transformaci√≥n se implement√≥ en `sp_limpieza.py`, dentro de la funci√≥n `rellenar_nulos_categoricas(df, columnas)`, aplicada en `columnas_categoricas.ipynb`.
üîπ **Ejemplo de uso:**
```python
from src.sp_limpieza import rellenar_nulos_categoricas
df_limpio = rellenar_nulos_categoricas(df, ["job", "marital", "education"])
```

## üî¢ 3 An√°lisis de Variables Categ√≥ricas
Se realiz√≥ una exploraci√≥n detallada de cada variable categ√≥rica, utilizando medidas estad√≠sticas y visualizaciones.
### üåü Estad√≠sticas Descriptivas
Para cada variable categ√≥rica, se calcularon:
- **Moda** (valor m√°s frecuente).
- **N√∫mero de valores √∫nicos.**
- **Frecuencia relativa de cada categor√≠a.**
| **Variable** | **Moda**  | **Valores √önicos** |
|-------------|----------|----------------|
| `job`       | admin.   | 12             |
| `marital`   | married  | 4              |
| `education` | secondary | 6             |
| `contact`   | cellular | 2              |

üîπ **Ejemplo de uso en el an√°lisis exploratorio:**
```python
from src.sp_eda import analisis_general_cat
analisis_general_cat(df_limpio)
```

## üåç 4 Visualizaci√≥n de Variables Categ√≥ricas
Para visualizar la distribuci√≥n de las categor√≠as, se cre√≥ la funci√≥n `graficar_categoricas(df)`, ubicada en `sp_visualizacion.py`.

üîπ **Ejemplo de uso:**
```python
from src.sp_visualizacion import graficar_categoricas
graficar_categoricas(df_limpio)
```
Los gr√°ficos generados est√°n en `columnas_categoricas.ipynb`.

## üîç 5 Conclusiones Tras la Visualizaci√≥n
üìå **An√°lisis de los gr√°ficos generados:**
- **`job`**: La ocupaci√≥n m√°s frecuente es "admin.", seguida de "blue-collar" y "technician". Esto indica una fuerte representaci√≥n de trabajadores administrativos y t√©cnicos.
- **`marital`**: El estado civil m√°s com√∫n es "married", lo que podr√≠a ser relevante si queremos analizar la estabilidad econ√≥mica de los clientes.
- **`education`**: La mayor√≠a de los clientes tienen educaci√≥n secundaria o universitaria, lo que puede influir en su perfil financiero.
- **`contact`**: Se observa que la mayor√≠a de las campa√±as se realizaron a trav√©s de tel√©fonos celulares, lo que puede influir en la tasa de respuesta.

üìå **Implicaciones para el an√°lisis:**
- La alta presencia de clientes casados y con educaci√≥n media/alta podr√≠a influir en su respuesta a productos financieros.
- El uso de celulares como principal medio de contacto sugiere que las campa√±as digitales pueden ser m√°s efectivas.
- La segmentaci√≥n por tipo de ocupaci√≥n podr√≠a ayudar a personalizar las estrategias de marketing.


### 6Ô∏è‚É£ Eliminaci√≥n de `poutcome`
Dado que la variable `poutcome` ten√≠a un **86%** de valores nulos, se decidi√≥ eliminarla. Antes de tomar esta decisi√≥n, se evalu√≥ su impacto en la variable objetivo (`y`):
- Se gener√≥ una tabla de frecuencias cruzadas con:
  ```python
  pd.crosstab(df['poutcome'], df['y'], normalize='index')
  ```
- Se identific√≥ que los datos disponibles en `poutcome` no influ√≠an significativamente en la variable `y`.

üìå **Conclusi√≥n:**  
La eliminaci√≥n de `poutcome` **no afect√≥ el an√°lisis**, ya que la cantidad de datos faltantes sesgaba la distribuci√≥n.

---

### 7Ô∏è‚É£ Guardado del Dataset Limpio
Tras completar la limpieza, se guard√≥ el dataset con las modificaciones aplicadas:

```python
df_limpio.to_csv("data/bank_limpio.csv", index=False)
```

### üìå 5Ô∏è‚É£ Quinta sesi√≥n: An√°lisis Preliminar de Columnas Num√©ricas


#### üî¢ **Exploraci√≥n de las columnas num√©ricas**
Se realiz√≥ un an√°lisis exploratorio sobre las columnas num√©ricas, examinando su distribuci√≥n, valores at√≠picos y diferencias entre medidas de tendencia central.

üìå **Garant√≠a:**  
Esto asegura que todas las transformaciones y ajustes en valores nulos **se reflejen correctamente** en el dataset final.

### **5 Quinta Sesi√≥n: An√°lisis de Variables Num√©ricas**

---

## üî¢ **Exploraci√≥n de las Columnas Num√©ricas**
Se realiz√≥ un an√°lisis exploratorio de las variables num√©ricas para comprender su distribuci√≥n, detectar valores at√≠picos y evaluar su impacto en el an√°lisis.

üìå **Pasos realizados:**

- Se calcularon estad√≠sticas descriptivas usando:

 ```python
df.describe().T
```


- Se identificaron columnas con alta dispersi√≥n entre la media y la mediana.
- Se visualizaron histogramas y boxplots para detectar outliers en variables clave.

**Boxplots y distribuci√≥n de los datos**
- Para identificar valores at√≠picos en las variables num√©ricas, se crearon gr√°ficos de caja (boxplots), lo que permiti√≥:
- Detectar columnas con valores extremos, como duration y campaign.

## üîπ Gesti√≥n de valores nulos
Se realiz√≥ un an√°lisis de valores nulos en el dataset y se tomaron las siguientes decisiones:
‚úÖ **Sustituci√≥n de nulos en columnas num√©ricas**:
   - `age` ‚Üí **Sustituido por la mediana** (38.0).
   - `duration` ‚Üí **Sustituido por la mediana** (179.0).
   - Resto de columnas num√©ricas **se mantienen con NaN** para futuras decisiones.
‚úÖ **Sustituci√≥n de nulos en columnas categ√≥ricas**:
   - Se reemplazaron valores nulos en variables categ√≥ricas con `'unknown'` para evitar la p√©rdida de informaci√≥n.
Los cambios fueron implementados en el script `src/sp_limpieza.py` dentro de la funci√≥n `rellenar_nulos_numericas`.

**Comparaci√≥n de correlaciones**
Correlaciones entre Variables
‚úÖ Calculamos la matriz de correlaciones entre las variables num√©ricas.
‚úÖ Identificamos relaciones destacadas como:

emp_var_rate y euribor3m con una correlaci√≥n de 0.82, lo que indica una fuerte relaci√≥n entre estas variables.

campaign y previous tienen una correlaci√≥n muy baja, lo que sugiere que las interacciones previas con clientes no afectan significativamente el n√∫mero de intentos en la campa√±a actual.

 **Outliers (Valores At√≠picos)**
‚úÖ Identificamos outliers en varias columnas, especialmente en duration, campaign y pdays.
‚úÖ No eliminamos los outliers, ya que podr√≠an representar informaci√≥n valiosa para el an√°lisis.
‚úÖ Mencionamos en el informe que, en futuros an√°lisis, se puede considerar tratarlos dependiendo del enfoque del negocio.

**Observaciones y Pr√≥ximos Pasos**
Algunas variables presentan alta correlaci√≥n.
Se encontraron valores at√≠picos en duration y campaign, lo que requerir√° un tratamiento especial.
El an√°lisis de outliers y su impacto en el modelo ser√° evaluado en sesiones posteriores.
** Conclusiones principales:**
‚úÖ La duraci√≥n de la √∫ltima campa√±a (duration) presenta una gran variabilidad y valores extremos.
‚úÖ Algunas variables presentan correlaciones fuertes, lo que puede ayudar a definir estrategias de segmentaci√≥n de clientes.
‚úÖ La presencia de outliers indica que existen casos excepcionales que podr√≠an analizarse con m√°s detalle.

El dataset actualizado sigue estando disponible como bank_limpio.csv en la carpeta data/.
---

### üíæ **Guardado de Datos**

  ```

- Se identificaron columnas con alta dispersi√≥n entre la **media y la mediana**.
- Se visualizaron **histogramas** y **boxplots** para detectar outliers en variables clave.

üëâ **Boxplots y Distribuci√≥n de Datos**  
Para identificar valores at√≠picos, se crearon gr√°ficos de caja (**boxplots**), lo que permiti√≥:

- Detectar columnas con valores extremos, como **`duration`** y **`campaign`**.
- Identificar patrones inusuales en variables como **`pdays`**, donde el valor **999** es recurrente.

üìå **Hallazgos principales:**
- **La edad (`age`) muestra una distribuci√≥n centrada en 38 a√±os**, con valores m√≠nimos de 17 y m√°ximos de 98.
- **`pdays` presenta un valor at√≠pico frecuente de 999**, lo que sugiere que representa clientes que no han sido contactados antes.
- **`nr_employed` tiene valores at√≠picos, pero no es una variable de riesgo, ya que parece reflejar un ID o referencia interna.**

---

## üîπ **Gesti√≥n de Valores Nulos**

Se realiz√≥ un an√°lisis de valores nulos en el dataset y se tomaron las siguientes decisiones:

üìå **Sustituci√≥n de valores nulos en columnas num√©ricas:**

| **Columna**  | **% de Nulos** | **M√©todo de Imputaci√≥n** | **Justificaci√≥n** |
|-------------|---------------|-------------------------|-------------------|
| `age`       | 11.9%         | **Mediana (38.0)**      | La mediana es robusta ante outliers y representa mejor la distribuci√≥n de la edad. |
| `duration`  | 0.0%          | **Sin cambios**         | No hay valores nulos en esta columna. |
| `pdays`     | 0.0%          | **Sin cambios**         | Aunque presenta valores at√≠picos, no tiene valores nulos. |
| `previous`  | 0.0%          | **Sin cambios**         | Se mantiene sin modificaciones. |

üìå **¬øPor qu√© se us√≥ la mediana en `age`?**
- La **mediana** es menos sensible a los valores extremos que la media.
- La distribuci√≥n de la edad es **asim√©trica**, por lo que la mediana es m√°s representativa del valor central real.
- Permite preservar la estructura de los datos sin sesgarlos hacia valores extremos.

üìå **Implementaci√≥n en c√≥digo:**

```python
from src.sp_limpieza import rellenar_nulos_numericas
df_limpio = rellenar_nulos_numericas(df_limpio, ["age"])
```

---

## üî¢ **Detecci√≥n de Outliers**

Se utiliz√≥ el **Rango Intercuartil (IQR)** para identificar valores at√≠picos en cada variable.

üìå **C√°lculo del IQR:**

```python
Q1 = df_numericas.quantile(0.25)  # Primer cuartil (25%)
Q3 = df_numericas.quantile(0.75)  # Tercer cuartil (75%)
IQR = Q3 - Q1  # Rango intercuartil
limite_inferior = Q1 - 1.5 * IQR
limite_superior = Q3 + 1.5 * IQR
outliers = (df_numericas < limite_inferior) | (df_numericas > limite_superior)
outliers.sum()
```

üìå **Conclusi√≥n sobre outliers:**
‚úÖ **No se detectaron valores at√≠picos que sean preocupantes.**  
‚úÖ Aunque hay algunas variables con valores extremos, estos no afectan el an√°lisis de manera significativa.  
‚úÖ **En futuros an√°lisis, se podr√≠a evaluar si eliminarlos o categorizarlos para mejorar la interpretaci√≥n.**  

---

## üî¢ **Matriz de Correlaci√≥n y An√°lisis de Relaciones**

Se gener√≥ la **matriz de correlaci√≥n** para identificar relaciones entre variables.

üìå **Hallazgos clave:**
- **`previous` y `pdays` est√°n altamente correlacionadas (-0.59)**  
  - `pdays` indica **los d√≠as desde el √∫ltimo contacto** con el cliente.
  - `previous` indica **el n√∫mero de contactos previos** en la campa√±a.
  - Esto sugiere que clientes con **pocos contactos anteriores tienen un `pdays` alto** y viceversa.

üìå **Visualizaci√≥n en c√≥digo:**

```python
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10,8))
sns.heatmap(df_numericas.corr(), annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Matriz de Correlaciones")
plt.show()
```

---

## üíæ **Guardado del Dataset**


El dataset limpio y procesado se guard√≥ en la carpeta `data` bajo el nombre `bank_limpio.csv`.  

üìå **C√≥digo de guardado:**

```python
df_limpio.to_csv("../data/bank_limpio.csv", index=False)
```

---

## üìå **Conclusiones Finales**
‚úÖ **La variable `age` fue imputada con la mediana (38 a√±os) para evitar sesgo por valores extremos.**  
‚úÖ **Se detectaron outliers, pero no afectan significativamente el an√°lisis.**  
‚úÖ **La matriz de correlaci√≥n indica que `pdays` y `previous` est√°n altamente relacionadas, lo que podr√≠a justificar su consolidaci√≥n.**  
‚úÖ **El dataset actualizado sigue estando disponible como `bank_limpio.csv` en la carpeta `data/`.**  


# üìå Recomendaciones Basadas en el An√°lisis

### 1Ô∏è‚É£ üìû Optimizaci√≥n del Canal de Contacto
- Se ha identificado que la mayor√≠a de los clientes fueron contactados a trav√©s de **tel√©fonos m√≥viles**.  
- Dado que este canal es el m√°s utilizado, se recomienda **priorizar las campa√±as a trav√©s de llamadas m√≥viles** y explorar estrategias complementarias como **mensajes SMS o WhatsApp** para mejorar la tasa de respuesta.

### 2Ô∏è‚É£ üéì Personalizaci√≥n Seg√∫n Nivel Educativo
- Se observ√≥ que los clientes con **educaci√≥n secundaria y universitaria** representan la mayor proporci√≥n.  
- Esto sugiere que las estrategias de marketing pueden enfocarse en este grupo, **adaptando el lenguaje y las ofertas** para que sean m√°s atractivas a personas con estos niveles educativos.

### 3Ô∏è‚É£ üìä Segmentaci√≥n por Edad
- La edad de los clientes var√≠a ampliamente, pero existen grupos predominantes.  
- Ser√≠a beneficioso analizar con m√°s detalle qu√© **segmentos de edad responden mejor a las campa√±as**, permitiendo personalizar ofertas y mensajes seg√∫n el perfil generacional.

### 4Ô∏è‚É£ üíç Estado Civil y Perfil del Cliente
- La mayor√≠a de los clientes contactados est√°n **casados**.  
- Dado que las decisiones financieras pueden verse influenciadas por la situaci√≥n familiar, ser√≠a interesante explorar si este grupo tiene **mayor disposici√≥n** a contratar ciertos productos financieros (como hipotecas o planes de ahorro familiares).

### 5Ô∏è‚É£ üìà Optimizaci√≥n de la Duraci√≥n de la Llamada
- Se encontr√≥ que la variable **duration** (duraci√≥n de la llamada) tiene un impacto significativo en la respuesta del cliente.  
- Se recomienda analizar con m√°s profundidad qu√© **duraciones √≥ptimas** maximizan la conversi√≥n, para ajustar los scripts de llamadas y mejorar la eficiencia del equipo de ventas.

### 6Ô∏è‚É£ üîÅ Frecuencia de Contacto y Respuesta
- La variable **campaign** mostr√≥ que algunos clientes fueron contactados varias veces en la misma campa√±a.  
- Se sugiere evaluar cu√°l es el **n√∫mero √≥ptimo de intentos de contacto** para evitar insistencia excesiva y fatiga del cliente.

### 7Ô∏è‚É£ üìÖ An√°lisis Temporal de la Campa√±a
- Se podr√≠a realizar un an√°lisis de estacionalidad para identificar **los mejores meses o d√≠as de la semana** para contactar clientes, mejorando la efectividad de la campa√±a.

---

## üèÜ **Conclusi√≥n Final**
Este an√°lisis ha permitido identificar **patrones clave** en los clientes contactados, lo que facilita la **segmentaci√≥n estrat√©gica** y la mejora de las campa√±as de marketing.  

La personalizaci√≥n de los mensajes seg√∫n **edad, estado civil, nivel educativo y canal de contacto** puede **incrementar las tasas de conversi√≥n** y optimizar los recursos de la campa√±a.  



